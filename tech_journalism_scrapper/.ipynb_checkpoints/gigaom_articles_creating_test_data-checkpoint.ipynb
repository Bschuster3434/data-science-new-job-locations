{
 "metadata": {
  "name": ""
 },
 "nbformat": 3,
 "nbformat_minor": 0,
 "worksheets": [
  {
   "cells": [
    {
     "cell_type": "code",
     "collapsed": false,
     "input": [
      "import sqlite3\n",
      "import time\n",
      "from goose import Goose\n",
      "import pickle\n",
      "import pandas as pd\n",
      "import re\n",
      "from nltk import sent_tokenize, word_tokenize\n",
      "import csv"
     ],
     "language": "python",
     "metadata": {},
     "outputs": [],
     "prompt_number": 9
    },
    {
     "cell_type": "code",
     "collapsed": false,
     "input": [
      "def search_sents_for_google_locations(link_sql, csv_output):\n",
      "    \"\"\"\n",
      "    Main Function for Article Scrapper. Takes a sql script with all the urls to be searched\n",
      "    and searched the articles for mentions of any city states from Google's list online.\n",
      "    \n",
      "    CSV from the google page with the cities and states:\n",
      "    https://developers.google.com/adwords/api/docs/appendix/geotargeting?csw=1\n",
      "    \n",
      "    Returns a CSV with all the sentences and each mention of a city state in the article.\n",
      "    If no city states are mentioned, the 2nd column will be blank.    \n",
      "    \"\"\"\n",
      "    \n",
      "    all_article_urls = grab_available_urls(link_sql)\n",
      "    all_article_contents = [grab_article_content(url) for url in all_article_urls]\n",
      "    \n",
      "    google_cs_list = city_state_names()\n",
      "    \n",
      "    for next_content in all_article_contents:\n",
      "        sents_with_locations = []\n",
      "        sents = sent_tokenize(next_content)\n",
      "        for next_sent in sents:\n",
      "            loc_tuple = find_google_cs(next_sent, google_cs_list)\n",
      "            for result in loc_tuple:\n",
      "                sents_with_locations.append(result)\n",
      "        df = pd.DataFrame(sents_with_locations)\n",
      "        df.to_csv(csv_output, header=False, index=False)"
     ],
     "language": "python",
     "metadata": {},
     "outputs": [],
     "prompt_number": 32
    },
    {
     "cell_type": "code",
     "collapsed": false,
     "input": [
      "def grab_available_urls(article_sql):\n",
      "    conn = sqlite3.connect(\"TechScrapper.db\")\n",
      "    c = conn.cursor()\n",
      "    c.execute(article_sql)\n",
      "    urls = [row[0] for row in c.fetchall()]\n",
      "    conn.close()\n",
      "    return urls"
     ],
     "language": "python",
     "metadata": {},
     "outputs": [],
     "prompt_number": 3
    },
    {
     "cell_type": "code",
     "collapsed": false,
     "input": [
      "def grab_article_content(url):\n",
      "    g = Goose()\n",
      "    article = g.extract(url=url)\n",
      "    content = article.cleaned_text.encode(\"ascii\", \"ignore\")\n",
      "    return content"
     ],
     "language": "python",
     "metadata": {},
     "outputs": [],
     "prompt_number": 4
    },
    {
     "cell_type": "code",
     "collapsed": false,
     "input": [
      "def city_state_names():    \n",
      "    f = \"gcs_US_City_States_Only.csv\"\n",
      "    df = pd.DataFrame.from_csv(f)\n",
      "    names = df.Name.unique()\n",
      "    return names"
     ],
     "language": "python",
     "metadata": {},
     "outputs": [],
     "prompt_number": 5
    },
    {
     "cell_type": "code",
     "collapsed": false,
     "input": [
      "def find_google_cs(sent, google_cs_list):\n",
      "    locations_found = []\n",
      "    for loc in google_cs_list:\n",
      "        all_finds = [m.start() for m in re.finditer(loc, sent)]\n",
      "        for loc_f in all_finds:\n",
      "            part_sent = sent[:loc_f] #Remove the location found in the sentence\n",
      "            part_tokenized_sent = word_tokenize(part_sent) #Count the count of tolkenized words\n",
      "            first_point = len(part_tokenized_sent) #The First location will\n",
      "            tokenize_loc = word_tokenize(loc) #tolkenize the location\n",
      "            last_point = first_point + len(tokenize_loc) - 1 #The last point will be the first point plus the lenght of tolken (-1)\n",
      "            locations_found.append((sent, loc, first_point, last_point)) #Add this to the list\n",
      "    if len(locations_found) == 0:\n",
      "        return [(sent, \"N/A\", -1, -1)]\n",
      "    else:\n",
      "        return locations_found"
     ],
     "language": "python",
     "metadata": {},
     "outputs": [],
     "prompt_number": 18
    },
    {
     "cell_type": "code",
     "collapsed": false,
     "input": [
      "def test():\n",
      "    sent_1 = \"I am the one who knocks in Utah.\"\n",
      "    sent_2 = \"I don't have any named states in here.\"\n",
      "    sent_3 = \"I am from San Francisco.\"\n",
      "    sent_4 = \"I am from Utah, and she too is from Utah.\"\n",
      "    sent_5 = \"Utah is my favorite\"\n",
      "    cities = [\"Omaha\", \"Utah\", \"Texas\", \"San Francisco\"]\n",
      "    assert find_google_cs(sent_1, cities)[0] == (\"I am the one who knocks in Utah.\", \"Utah\", 7, 7)\n",
      "    assert find_google_cs(sent_2, cities)[0] == (\"I don't have any named states in here.\", \"N/A\", -1, -1)\n",
      "    assert find_google_cs(sent_3, cities)[0] == (\"I am from San Francisco.\", \"San Francisco\" , 3, 4)\n",
      "    assert find_google_cs(sent_4, cities)[1] == (\"I am from Utah, and she too is from Utah.\", \"Utah\", 10, 10)\n",
      "    assert find_google_cs(sent_5, cities)[0] == (\"Utah is my favorite\", \"Utah\", 0, 0)\n",
      "    assert find_google_cs(sent_1, cities) == [((\"I am the one who knocks in Utah.\", \"Utah\", 7, 7))]\n",
      "    test_url = \"https://gigaom.com/2014/09/18/finally-meta-begins-shipping-its-augmented-reality-glasses-to-developers/\"\n",
      "    test_content = grab_article_content(test_url)\n",
      "    assert test_content[:5] == \"Its a\"\n",
      "    \n",
      "    return \"Test Passed\"\n",
      "\n",
      "test()"
     ],
     "language": "python",
     "metadata": {},
     "outputs": [
      {
       "metadata": {},
       "output_type": "pyout",
       "prompt_number": 34,
       "text": [
        "'Test Passed'"
       ]
      }
     ],
     "prompt_number": 34
    },
    {
     "cell_type": "code",
     "collapsed": false,
     "input": [],
     "language": "python",
     "metadata": {},
     "outputs": []
    }
   ],
   "metadata": {}
  }
 ]
}