{
 "metadata": {
  "name": ""
 },
 "nbformat": 3,
 "nbformat_minor": 0,
 "worksheets": [
  {
   "cells": [
    {
     "cell_type": "code",
     "collapsed": false,
     "input": [
      "from bs4 import BeautifulSoup\n",
      "import urllib2\n",
      "import sqlite3\n",
      "import pickle\n",
      "import time\n",
      "import re\n",
      "import os\n",
      "from goose import Goose"
     ],
     "language": "python",
     "metadata": {},
     "outputs": [],
     "prompt_number": 4
    },
    {
     "cell_type": "code",
     "collapsed": false,
     "input": [
      "location_sql = \"SELECT * FROM Articles WHERE ID not in (SELECT UrlId FROM LocationScrapped)\""
     ],
     "language": "python",
     "metadata": {},
     "outputs": [],
     "prompt_number": 7
    },
    {
     "cell_type": "code",
     "collapsed": false,
     "input": [
      "conn = sqlite3.connect(\"TechScrapper.db\")\n",
      "c = conn.cursor()\n",
      "c.execute(article_sql)"
     ],
     "language": "python",
     "metadata": {},
     "outputs": [
      {
       "metadata": {},
       "output_type": "pyout",
       "prompt_number": 8,
       "text": [
        "<sqlite3.Cursor at 0x834d2d0>"
       ]
      }
     ],
     "prompt_number": 8
    },
    {
     "cell_type": "code",
     "collapsed": false,
     "input": [
      "coors_path = os.path.abspath(os.path.join(os.path.curdir, \"..\", \"inc_5000_cities\"))\n",
      "with open(coors_path + \"\\\\city_state_coors.pickle\", \"U\") as f:\n",
      "    coors = pickle.load(f)\n",
      "with open(\"city_state_lookup.pickle\", \"U\") as f:\n",
      "    lookup = pickle.load(f)"
     ],
     "language": "python",
     "metadata": {},
     "outputs": []
    },
    {
     "cell_type": "code",
     "collapsed": false,
     "input": [
      "def grab_article_content(url):\n",
      "    g = Goose()\n",
      "    article = g.extract(url=url)\n",
      "    content = article.cleaned_text.encode(\"ascii\", \"ignore\")\n",
      "    return content"
     ],
     "language": "python",
     "metadata": {},
     "outputs": [],
     "prompt_number": 9
    },
    {
     "cell_type": "code",
     "collapsed": false,
     "input": [
      "def search_locations(content):        \n",
      "    cs_found = []\n",
      "    for key in lookup.iterkeys():\n",
      "        city_search = content.find(key)\n",
      "        if city_search >= 0:\n",
      "            cs_found.append(lookup[key])\n",
      "    return cs_found"
     ],
     "language": "python",
     "metadata": {},
     "outputs": [],
     "prompt_number": 5
    },
    {
     "cell_type": "code",
     "collapsed": false,
     "input": [
      "def add_locations(cs_found, url_id):\n",
      "    if len(cs_found) > 0:\n",
      "        for cs_i in cs_found:\n",
      "            v = coors[cs_i]\n",
      "            lat = v['lat']\n",
      "            lon = v['lon']\n",
      "            city = v['city']\n",
      "            state = v['state']\n",
      "            city_state = v['city_state']\n",
      "            c_2 = conn.cursor()\n",
      "            c_2.execute(\"INSERT INTO LocationCounts VALUES(?,?,?,?,?,?,?)\", (None, url_id, lat, lon, city, state, city_state))\n",
      "            try:\n",
      "                c_2.execute(\"INSERT INTO  LocationScrapped VALUES(?, ?)\", (None, url_id))\n",
      "            except:\n",
      "                continue\n",
      "            conn.commit()      "
     ],
     "language": "python",
     "metadata": {},
     "outputs": [],
     "prompt_number": 6
    },
    {
     "cell_type": "code",
     "collapsed": false,
     "input": [
      "def scrap_articles(notify=100):\n",
      "\n",
      "    start = time.time()\n",
      "\n",
      "    for n, row in enumerate(c.fetchall()):\n",
      "        if n % notify == 0:\n",
      "            print \"Now on Number \" + str(n) + \". Time Run in seconds: \" + str(time.time() - start)\n",
      "        url_id = row[0]\n",
      "        url = row[1]\n",
      "        content = grab_article_content(url)\n",
      "        cs_found = search_locations(content)\n",
      "        if cs_found != None:\n",
      "            add_locations(cs_found, url_id)\n",
      "        time.sleep(.2)\n",
      "    stop = time.time()\n",
      "    conn.close()\n",
      "    print \"Seconds to Complete: \" + str(stop - start)"
     ],
     "language": "python",
     "metadata": {},
     "outputs": [],
     "prompt_number": 7
    },
    {
     "cell_type": "code",
     "collapsed": false,
     "input": [
      "def test():\n",
      "    url = \"https://docs.python.org/2/tutorial/errors.html\"\n",
      "    content = grab_article_content(url)\n",
      "    assert content[:10] == 'Until now '\n",
      "    return \"Test Passed\""
     ],
     "language": "python",
     "metadata": {},
     "outputs": [],
     "prompt_number": 12
    }
   ],
   "metadata": {}
  }
 ]
}